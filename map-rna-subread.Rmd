---
title: "RNA-seq read alignment in R"
author: "Sam Buckberry"
date: "20/10/2021"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Once you are confident in the quality of the RNA-seq data, you can then move onto creating a matrix of read counts to use in differential expression testing. To do this, we first need to map the reads to a reference genome (or transcriptome), and then count the aligned reads with respect to gene annotations to calculate the number of reads mapping to each gene.

If the species under study has a well-annotated transcriptome, the reads can be aligned to the transcript sequences instead of the reference genome using tools such as [Kallisto](https://pachterlab.github.io/kallisto/about) or [Salmon](https://salmon.readthedocs.io/en/latest/salmon.html). When no good quality reference genome or transcriptome is available for the species being studied, you can *de novo* assemble transcripts using tools such as [Trinity](https://github.com/trinityrnaseq/trinityrnaseq/wiki) and then quantify the expression levels of genes/transcripts. However, the use of these tools is outside of the scope of this short workshop. 

For RNA-seq read alignments, apart from the availability of reference genomes and annotations, probably the most important factor to consider when choosing an alignment tool is whether the alignment method considers the absence of intronic regions in the sequenced reads, while the target genome may contain introns. Therefore, it is important to choose alignment tools that take into account alternative splicing. In the basic setting where a read, which originates from a cDNA sequence corresponding to an exon-exon junction, needs to be split into two parts when aligned against the genome.

There are various tools that consider this factor such as STAR, Hisat2, and Subread. As Subread is implimented in the `Rsubread` R package, we will use this tool here.

Load the libraries.
```{r}
library(Rsubread)
library(magrittr)
library(stringr)
library(DT)
library(rtracklayer)
library(Rsamtools)
library(stringr)
library(magrittr)
library(edgeR)
```

First, we need to index the reference genome by building the Rsubread alignment index. It is reccomended to use the option `gappedIndex = TRUE` on a personal computer that has limited memory capacity. 
```{r, cache=TRUE}
buildindex(basename="reference/GRCh38_chr22",
           gappedIndex = TRUE,
           reference="reference/Homo_sapiens.GRCh38.dna.chromosome.22.fa.gz")
```

Now we have the reference genome built, we can align the reads to our reference genome using the `Rsubread::align` function. 

Here is an example command to align one sample to the indexed reference genome using one thread. Here the inputs are the `.fastq.gz` files, and the output is a `.bam` file (no need to run). 
```{r, eval=FALSE}
align_dat <- align(index="GRCh38",
                   readfile1 = "1001-Effector_CD4pos_T-S_filt_fastp_R1.fastq.gz",
                   readfile2 = "1001-Effector_CD4pos_T-S_filt_fastp_R2.fastq.gz",
                   output_file="1001-Effector_CD4pos_T-S.BAM",
                   nthreads = 1)
```

To process all the samples at once, we can create a table of all input and output files and process the data by writing a function.  

First, we create the table of all the input and output files:  
```{r, cache=TRUE}
# function to align all samples

r1_list <- list.files("fastq/", pattern = "_filt_fastp_R1.fastq.gz",
                      full.names = TRUE)

r2_list <- list.files("fastq/", pattern = "_filt_fastp_R2.fastq.gz",
                      full.names = TRUE)

bam_list <- basename(r1_list) %>%
    str_replace("_R1.fastq.gz", ".bam")

dir.create("aligned_data")
bam_list <- str_c("aligned_data/", bam_list)

fq_df <- data.frame(r1 = r1_list, r2 = r2_list, bam = bam_list)

head(fq_df)
```

Double check all input files exist
```{r, cache=TRUE}
all(file.exists(c(r1_list, r2_list)))
```

And then write a function to align the data for each sample.  

Here we are using the `align` function which is applicable to both RNA-seq and DNA sequencing data.  
```{r, eval=FALSE}
# Function to align reads for each sample
align_list <- function(x){
  
  align(index="reference/GRCh38_chr22",
        type = "rna",
        sortReadsByCoordinates = TRUE,
        useAnnotation = TRUE,
        annot.ext = "reference/Homo_sapiens.GRCh38.104.chromosome.22.gtf.gz",
        isGTF = TRUE,
        readfile1= fq_df$r1[x],
        readfile2 = fq_df$r2[x],
        output_file = fq_df$bam[x],
        nthreads = 2)
}

# Apply function to list of samples
align_dat <- lapply(1:nrow(fq_df), align_list)
```

Or we could use the `subjunc` function that is designed for RNA-seq and will also report novel exon-exon junctions, and can be tailored to discover structural varaitions in the RNA-seq data. For more information on this, see the `subjunc` documentation by using the `?subjunc` command.  
```{r, cache=TRUE}
subjunc_list <- function(x){
  
  subjunc(index="reference/GRCh38_chr22",
        sortReadsByCoordinates = TRUE,
        useAnnotation = TRUE,
        annot.ext = "reference/Homo_sapiens.GRCh38.104.chromosome.22.gtf.gz",
        isGTF = TRUE,
        readfile1= fq_df$r1[x],
        readfile2 = fq_df$r2[x],
        output_file = fq_df$bam[x],
        nthreads = 1)
}

# Apply function to list of samples
map_dat <- lapply(1:nrow(fq_df), subjunc_list)
```

> **_Challenge:_** Try to align the reads by allowing multi-mappers (set unique = FALSE), and allow for up to 6 “best” locations to be reported (nBestLocations = 6). Specify the output file names in the `fq_df` object by substituting the `df_fq$bam` data with `df_fq$bam <- str_replace_all(string = df_fq$bam, pattern = ".bam", replacement = "_multi.bam")` so not to overwrite the unique alignment bam files. Then look at the proportion of reads mapped and see if we get any more reads mapping by specifying a less stringent criteria.

Convert alignment data into matrix and view as table. 
```{r, cache=TRUE}
map_dat <- do.call(cbind, map_dat)
datatable(data = map_dat)
```

Or use the `propmapped` function to check the proportion of aligned reads for all libraries. 
```{r, cache=TRUE}
props <- propmapped(files = fq_df$bam)
props
```

Now lets create the table of counts for genes and transcripts using the `featureCounts` function from Subread. 
```{r, cache=TRUE}
# Check BAM files exist
stopifnot(file.exists(fq_df$bam))

# Specify GTF file used for counts
gtf_path <- "reference/Homo_sapiens.GRCh38.104.chromosome.22.gtf.gz"

### Calculate gene counts
gene_counts <- featureCounts(files = fq_df$bam,
                             GTF.attrType = "gene_id",
                             annot.ext = gtf_path,
                             isGTFAnnotationFile = TRUE,
                             isPairedEnd = TRUE,
                             nthreads=16)

### Calculate transcript counts
tx_counts <- featureCounts(files = fq_df$bam,
                         GTF.attrType = "transcript_id",
                         annot.ext = gtf_path,
                         isGTFAnnotationFile = TRUE,
                         isPairedEnd = TRUE,
                         nthreads=16)
```

Inspect gene count statistics
```{r, cache=TRUE}
datatable(gene_counts$stat)
```

Inspect transcript count statistics
```{r, cache=TRUE}
datatable(tx_counts$stat)
```

Inspect the counts table
```{r, cache=TRUE}
head(gene_counts$counts)
```

Save the counts objects to use in downstream analyses.
```{r, cache=TRUE}
saveRDS(object = gene_counts, file = "processed_data/Effector_CD4pos_gene_counts_chr22.Rds")
saveRDS(object = tx_counts, file = "processed_data/Effector_CD4pos_transcript_counts_chr22.Rds")
```

### Make Bigwig coverage files

Bigwig coverage files can be used to generate many types of plots, including coverage heatmaps genome browser tracks

To make the bigwig coverage files from the bam alignments, first make a list of the bam files
```{r, cache=TRUE}
bams <- list.files(path = "aligned_data/", pattern = "_filt_fastp.bam$",
                   full.names = TRUE)
```

Then a function for making bigwig files from bam files
```{r, cache=TRUE}
bam_to_bigwig <- function(sorted_bam, CPM_normalise=TRUE){
    
    message(Sys.time())
    message(str_c("Processing ", sorted_bam))

    # Check inputs
    stopifnot(length(sorted_bam) == 1)
    stopifnot(length(CPM_normalise) == 1)
    stopifnot(file.exists(sorted_bam))
    stopifnot(is.logical(CPM_normalise))
    
    # Set outfile name
    out_path <- str_replace(string = sorted_bam,
                            pattern = ".bam$",
                            replacement = ".bigwig")
    
    # Use samtools to pileup reads
    message("Running samtools pileup...")
    param <- Rsamtools::PileupParam(distinguish_strands=FALSE,
                                distinguish_nucleotides = FALSE,
                                max_depth=10000,
                                min_base_quality=0)

    pileup_dat <- Rsamtools::pileup(file = sorted_bam,
                          pileupParam = param)
    
    # Convert to GRanges
    gr <- GRanges(seqnames = pileup_dat$seqnames,
                  ranges = IRanges(start = pileup_dat$pos,
                                   end = pileup_dat$pos))
    
    # Get contig/chromosome lengths from BAM file
    idx <- Rsamtools::idxstatsBam(sorted_bam)
    used_seqlengths <- idx$seqlength
    names(used_seqlengths) <- idx$seqnames
    seqlengths(gr) <- used_seqlengths

    # Normalise the data
    if (CPM_normalise == TRUE){
        message("Normalising data...")
        pileup_dat$cpm <- edgeR::cpm(y = pileup_dat$count) %>% as.numeric()
        gr$score <- as.numeric(pileup_dat$cpm)
    } else if (CPM_normalise == FALSE){
        gr$score <- as.numeric(pileup_dat$count)
    }
    
    # Add strand info
    strand(gr) <- "+"

    # Write the output file
    message(str_c("Writing ", out_path))
    export.bw(object = gr, con = out_path)
    message("Done!")
}

lapply(X = bams, FUN = bam_to_bigwig)
```

===

```{r}
sessionInfo()
```


